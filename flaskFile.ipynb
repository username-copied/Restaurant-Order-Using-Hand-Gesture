{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83885e-dbda-419f-812e-b440056919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the pre-trained CNN model for hand gesture recognition\n",
    "model = load_model('path/to/your/pretrained_model.h5')  # Replace with the path to your model\n",
    "\n",
    "# Dictionary to map gesture labels to menu items or commands\n",
    "gesture_menu_mapping = {\n",
    "    0: \"Pizza\",\n",
    "    1: \"Burger\",\n",
    "    2: \"Pasta\",\n",
    "    3: \"Salad\",\n",
    "    4: \"Sandwich\",\n",
    "    5: \"Sushi\",\n",
    "    6: \"Taco\",\n",
    "    7: \"Hot Dog\",\n",
    "    8: \"Ice Cream\",\n",
    "    9: \"French Fries\",\n",
    "    10: \"Chicken Wings\",\n",
    "    11: \"Steak\",\n",
    "    12: \"Soup\",\n",
    "    13: \"Dumplings\",\n",
    "    14: \"Noodles\",\n",
    "    15: \"Fried Rice\",\n",
    "    16: \"Fish and Chips\",\n",
    "    17: \"Fried Chicken\",\n",
    "    18: \"Shrimp\",\n",
    "    19: \"Nachos\",\n",
    "    20: \"Cheese\",\n",
    "    21: \"Vegetables\",\n",
    "    22: \"Fruit\",\n",
    "    23: \"Cake\",\n",
    "    24: \"Coffee\",\n",
    "    25: \"Tea\"\n",
    "}\n",
    "\n",
    "\n",
    "# Function to preprocess the image and perform prediction\n",
    "def predict_gesture(image):\n",
    "    # Preprocess the image (resizing, normalization, etc.)\n",
    "    # Depending on the model architecture, you may need to resize the image and normalize pixel values\n",
    "    image = cv2.resize(image, (128, 128))  # Modify the size as per your model input shape\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Perform prediction using the loaded model\n",
    "    prediction = model.predict(image)\n",
    "    gesture_label = np.argmax(prediction)\n",
    "    return gesture_label\n",
    "\n",
    "# Function to capture frames from the webcam\n",
    "def capture_frames():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gesture_label = predict_gesture(gray)\n",
    "        gesture = gesture_menu_mapping[gesture_label]\n",
    "        cv2.putText(frame, gesture, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Convert frame to JPEG format for web display\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame_jpg = buffer.tobytes()\n",
    "\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame_jpg + b'\\r\\n')\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')  # Create 'index.html' with your web interface design\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(capture_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
